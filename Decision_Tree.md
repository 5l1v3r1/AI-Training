# Decision Tree
Also known as CART (Classification and Regression Tree)

Root Node must be divided into child nodes and height of the tree should be optimal to get optimal solution.
Less depth can result into under fitting and more can result into over fitting.

### Pruning: Cutting down of branches that have low impact on output to overcome over fitting.


## Advantages:
Easy to visualise
Less time complexity
Efficient than other Algorithms if data size is small.

## Disadvantages:
It tends to over fit.
Not Efficient for large data sizes.
