{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return max(0.2*x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (exp(2*x)-1)/(exp(2*x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_sigmoid(x):\n",
    "    return (x*(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[0,1,1],[0,1,1],[1,0,1],[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[0.001,0.01,0.1,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Alpha= 0.001\n",
      "Error after 0 iteration 0.5057396017649606\n",
      "Error after 10000 iteration 0.49871900699374816\n",
      "Error after 20000 iteration 0.49813893226720163\n",
      "Error after 30000 iteration 0.4974287227741244\n",
      "Error after 40000 iteration 0.4963830685509847\n",
      "Error after 50000 iteration 0.4948263207064896\n",
      "\n",
      "Training with Alpha= 0.01\n",
      "Error after 0 iteration 0.507727111864833\n",
      "Error after 10000 iteration 0.4682732691036203\n",
      "Error after 20000 iteration 0.36236524331797915\n",
      "Error after 30000 iteration 0.30815400206887156\n",
      "Error after 40000 iteration 0.2896657384344451\n",
      "Error after 50000 iteration 0.280986240243296\n",
      "\n",
      "Training with Alpha= 0.1\n",
      "Error after 0 iteration 0.5047212426609363\n",
      "Error after 10000 iteration 0.2665683580518169\n",
      "Error after 20000 iteration 0.26050233375451876\n",
      "Error after 30000 iteration 0.25819709012330105\n",
      "Error after 40000 iteration 0.25691375722377974\n",
      "Error after 50000 iteration 0.25607341409530826\n",
      "\n",
      "Training with Alpha= 1\n",
      "Error after 0 iteration 0.5062829306424307\n",
      "Error after 10000 iteration 0.2540520255706406\n",
      "Error after 20000 iteration 0.2527612937676756\n",
      "Error after 30000 iteration 0.25221506205691413\n",
      "Error after 40000 iteration 0.2518968345053072\n",
      "Error after 50000 iteration 0.2516828740566053\n",
      "\n",
      "Training with Alpha= 10\n",
      "Error after 0 iteration 0.5007762360350099\n",
      "Error after 10000 iteration 0.25114481959554336\n",
      "Error after 20000 iteration 0.2507919162663423\n",
      "Error after 30000 iteration 0.25063920815322854\n",
      "Error after 40000 iteration 0.25054983734601094\n",
      "Error after 50000 iteration 0.25048956703305936\n",
      "\n",
      "Training with Alpha= 100\n",
      "Error after 0 iteration 0.5084136411465839\n",
      "Error after 10000 iteration 0.5000009764101059\n",
      "Error after 20000 iteration 0.5000004850238856\n",
      "Error after 30000 iteration 0.5000003224695895\n",
      "Error after 40000 iteration 0.5000002414518339\n",
      "Error after 50000 iteration 0.5000001929332624\n",
      "\n",
      "Training with Alpha= 1000\n",
      "Error after 0 iteration 0.5073469381222879\n",
      "Error after 10000 iteration 0.5000000250169974\n",
      "Error after 20000 iteration 0.5000000125249917\n",
      "Error after 30000 iteration 0.5000000083599381\n",
      "Error after 40000 iteration 0.5000000062771889\n",
      "Error after 50000 iteration 0.5000000050274581\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas:\n",
    "    print(\"\\nTraining with Alpha=\",str(alpha))\n",
    "    synapse_0=np.random.random((3,4)) # 3 corresponds to inputs and 4 to hidden layers\n",
    "    synapse_1=np.random.random((4,1)) #4 corresponds to hidden layers and 1 to output\n",
    "    \n",
    "    for j in range(60000): #60000 epochs ie. Iterations\n",
    "        layer_0=x\n",
    "        layer_1=sigmoid(np.dot(layer_0,synapse_0)) #dot product\n",
    "        layer_2=sigmoid(np.dot(layer_1,synapse_1)) \n",
    "        \n",
    "        layer_2_error= layer_2-y\n",
    "        \n",
    "        if j%10000==0:\n",
    "            print(\"Error after \"+str(j)+\" iteration \"+str(np.mean(np.abs(layer_2_error))))\n",
    "        \n",
    "        layer_2_delta=layer_2_error*d_sigmoid(layer_2)\n",
    "        \n",
    "        layer_1_error=layer_2_delta.dot(synapse_1.T) # T= Transpose\n",
    "        \n",
    "        layer_1_delta=layer_1_error*d_sigmoid(layer_1)\n",
    "        \n",
    "        synapse_1-=alpha*(layer_1.T.dot(layer_2_delta))\n",
    "        \n",
    "        synapse_0-= alpha*(layer_0.T.dot(layer_1_delta))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
